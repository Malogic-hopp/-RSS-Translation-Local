<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>科学直接出版：信息融合</title>
    <link>https://www.sciencedirect.com/journal/information-fusion</link>
    <description>科学直接RSS</description>
    <lastBuildDate>Wed, 14 Jan 2026 18:02:21 GMT</lastBuildDate>
    <item>
      <title><![CDATA[基于自适应融合的同构和异构模态多模态情感识别统一框架]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011340?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年5月来源：信息融合，第129卷作者：Abeer A.Wafa、Marwa s.Farhan、Mai M.Eldefrawi]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011340?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:38 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[Exo-to-Ego视频生成的渐进时间补偿和语义增强]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011790?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：王星跃、胡伟鹏、胡久田、李建辉、胡萍、谭亚鹏]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011790?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:35 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[HFPN：用于视听事件定位的具有多级跨模态关系学习的分层融合和预测网络]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S156625352501173X?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：张朴芬、贾磊、王嘉祥、孟婉、张四杰、张天乐、彭石]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S156625352501173X?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:32 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态情绪分析和总结的范围综述：最新进展、挑战和未来方向]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011443?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：藤本忠利、里卡多·马孔德斯·马卡奇尼、索兰奇·奥利维拉·雷森德]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011443?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:30 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[FedEGL：边缘辅助联邦图学习]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011807?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：王海涛、罗奥杰、徐文超、王浩钊、李一晨、齐怡宁、张睿、李瑞璇]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011807?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:28 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[EPSO-net：一种基于PSO引导的突变融合的多目标进化神经结构搜索，用于可解释的脑肿瘤分割]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011819?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：信息融合，第130卷作者：Farhana Yasmin，Yu Xue，Mahade Hasan，Ghulam Muhammad]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011819?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:26 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[反思：从跨模态哈希的角度揭示语义分布转移的影响]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253526000023?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：李沂南、刘志、唐家军、陈炳红、夸明进、龙军、詹阳]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253526000023?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:23 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[SG-DGLF：一个基于相似性的对偶图学习框架]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253526000060?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：于梦林、陆淑霞、丛佳]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253526000060?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:21 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[区域战胜全球：一种基于卷积架构的多光谱目标检测高效区域特征融合]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011728?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：信息融合，第130卷作者：王振浩，田]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011728?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:19 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[血管内手术中自主导丝导航的多模态大语言模型分层信息策略融合框架]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011777?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：王浩宇、姚、李、高、孙杭玲、周晨宇、李、傅强强、王宇、陈斌]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011777?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:17 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[通过专家自适应混合检测少数镜头有害模因]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253526000011?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：邹莉、廖金志、李季婷、王季、向赵]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253526000011?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:15 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[DAK-Pose：用于基于可推广视频的3D人体姿态估计的双增广器知识融合]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011625?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：王亚川、张斌、袁浩]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011625?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:12 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[GULSTSVM:双SVM中图信息和通用学习的融合]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011765?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：信息融合，第130卷作者：巴拉特·里查里亚，M.Tanveer，丁卫平]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011765?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:10 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于异构图学习框架的旋转机械多模态多工况故障诊断]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011686?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：韩晓宇、曹云鹏、潘虎、冯伟星]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011686?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:08 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[SynJAC：用于领域特定扫描文档关键信息提取的合成数据驱动联合粒度自适应和校准]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011364?dgcid=rss_sd_all</link>
      <description><![CDATA[出版日期：2026年6月来源：《信息融合》第130卷作者：丁一浩、韩素妍、李泽川、钟]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011364?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 16:25:06 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于多传感器数据融合的联合学习水流预报]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525010826?dgcid=rss_sd_all</link>
      <description><![CDATA[水文流量预报对于水资源管理、灾害预警和生态保护至关重要。然而，集中式建模方法面临着数据异构性、极端事件样本稀缺和隐私约束等持续挑战。这份手稿展示了一种融合异构、分布式水文数据的新范式，同时保护隐私，创建了一个比孤立数据孤岛更强大、更全面的模型。我们提出了联邦学习多站融合（FedMSF），它将局部模型与全局聚合集成在一起，在不暴露原始数据的情况下处理跨流域的变化。近端项减少了分布变化下的训练偏差，多目标聚合策略（FedMOA）自适应地对客户端进行加权以提高结构一致性。此外，极端感知数据增强丰富了罕见事件的表示，而人工智能驱动的大型语言模型（LLM）指导超参数优化。所有报告的指标都代表了所有集水区的平均表现。在CAMELS-GB西部地区的实验表明，FedMOA的RMSE为0.4322，MAE为0.2358，NSE为0.8371，分别比现有方法高出7.93%、9.20%和7.83%。此外，KGE提高了4.48%，达到0.8127，而FLV和FHV分别降低了24.38%和34.7%，表明体积误差减少了。通过整合增强和LLM驱动的优化，FedMSF进一步提高了性能，NSE达到0.8406，在跨区域水文预报中表现出更强的鲁棒性和泛化能力。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525010826?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:23 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[ViP-HMNN：一种结合记忆计算的视觉路径启发混合神经网络，用于对象识别]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011480?dgcid=rss_sd_all</link>
      <description><![CDATA[人工神经网络（Ann）和尖峰神经网络（SNN）的集成对于推进通用人工智能（AGI）具有重要的潜力。然而，混合神经网络（HNN）的硬件设计仍然主要依赖于近记忆计算架构，这尚未完全克服处理和存储单元之间的分离。为了解决这个问题，我们开发了一种视觉路径启发的混合忆阻神经网络（ViP-HMNN）。具体来说，我们设计了一种通用且紧凑的基于忆阻器的神经元电路，可以有效地实现ANN和SNN激活功能，作为所提出的ViP-HMNN的核心组件。为了提高对所设计的ViP-HMNN的理解，提出了一种腹侧通路启发的静态特征提取模块（VP-SFEM）、背侧通路激发的动态特征表示模块（DP-DFRM）和互补特征融合输出模块（CFFOM）。为了验证，将提出的具有协同混合训练策略的ViP-HMNN应用于目标识别。与基于软件的对象识别方法相比，所提出的ViP-HMNN实现了软件兼容的准确性（排名前三），并且在时间消耗方面具有显著优势（至少快8倍）。与内存计算架构相比，所提出的ViP-HMNN在面积开销、延迟和能耗方面分别提高了2.65倍、1.83倍和1.87倍。与RTX 3090 GPU相比，所提出的ViP HMNN的延迟至少减少了1000倍，节能了500倍。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011480?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:18 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[FedExIT-缺少类不可知的半监督联邦学习，具有极端不平衡的解决方案]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S156625352501142X?dgcid=rss_sd_all</link>
      <description><![CDATA[大多数联合学习方案都假设所有客户端要么拥有完全注释的、平衡的数据，要么标签属于每个客户端的同一组类。在本文中，我们致力于建立一个更通用、更现实、更实用的框架，放宽了两个假设，以适应：（a）大多数客户端中没有带注释的数据，（b）非IID客户端数据分布，（c）高度不平衡的客户端类分布，以及（d）不同客户端中缺少类的非相同客户端类集。为此，我们提出了FedExIT（Fed-ored Learning with Ex treme I mbalance T ackling），它有三个组成部分。首先，它包括一个理论上有根据的阶级间邻近系数，以解决严重的不平衡和阶级缺失问题。此外，对于未标记的客户，FedExIT引入了置信区间加权双均值教师，该教师在两个教师模型的不确定性感知指导下训练学生模型。由于常用的均值教师在早期培训阶段相当不稳定，我们利用一个基础模型DINOv2作为辅助教师，该模型在标记的客户端上进行了微调。为了进一步减少分类器偏差，FedExIT利用客户端自适应分类器微调策略，在每个客户端的特征空间中围绕全局原型生成平衡的合成嵌入。我们使用七个著名的数据集进行实验，包括（i）3个总体平衡数据集，即SVHN、CIFAR-10和CIFAR-100;（ii）3个总体不平衡的数据集，即CIFAR-10 LT、CIFAR-100 LT和ISIC-2018，以及（iii）一个包含10000个类的大型数据集iNaturalist 2021（用于检查可扩展性）。我们模拟了几个具有不同客户端数量、标记客户端比例和异质性程度的FL设置，证明了FedExIT优于10种基线方法。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S156625352501142X?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:16 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[收缩很重要：来自回归集成中准确性与多样性权衡的证据]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011352?dgcid=rss_sd_all</link>
      <description><![CDATA[回归集成是一种有竞争力的机器学习技术，近年来越来越受欢迎。流行的集成方案已经从利用简单平均值的等权重（EW）发展到通过最小化均方误差（MSE）来优化权重的最优权重（OWs）。广泛的研究不仅验证了电子战的鲁棒性，还引入了收缩的概念，将OWs向电子战收缩。本文通过多样性理论来解决集成挑战，其中集成MSE被分解为两个部分：全局误差和全局多样性。在分解框架内，OWs通常以降低全局分集为代价来最小化全局误差，而EWs倾向于最大化全局分集，但往往忽略准确性。为了解决精度与多样性的权衡问题，我们推导出了一个最优收缩因子，该因子能够最小化集合MSE。模拟结果揭示了收缩权重的中介作用，在六个UCI数据集和布伦特月度期货价格上的实证实验证明了所提出方法的优越性，并通过对收缩成分的深入分析进一步阐述了其机制。总的来说，我们的方法为回归集合中收缩的有效性提供了一个新的视角。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011352?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:13 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[FuseMeter：通用流量流量测量的有效框架]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011273?dgcid=rss_sd_all</link>
      <description><![CDATA[现代高速网络需要实时流量分析，但现有的按流量测量解决方案效率低下，缺乏处理各种同时任务的通用性。它们依赖于部署多个专用算法，考虑到网络处理器的严格资源限制，这会导致冗余计算和巨大的开销。为了解决这个问题，我们提出了FuseMeter，这是一种通用的按流量测量框架，可以在单个框架内同时支持具有不同类型和定义的异构任务。我们的设计采用多对象采样来自适应地管理不同任务类型的资源，并采用超立方体计数器来有效地集成多维记录。这个统一的管道能够快速、灵活地恢复所有部署任务的流量统计数据。我们在可编程硬件平台上对FuseMeter进行原型制作，并为其性能提供可配置的概率保证。在现实世界的互联网痕迹上进行的实验表明，FuseMeter的表现优于最先进的基准测试。它将估计误差减少了95.41%，内存开销减少了70.66%，处理速度比现有方法快12.39倍。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011273?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:11 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[曼巴的全面调查和分类：应用、挑战和未来方向]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S156625352501156X?dgcid=rss_sd_all</link>
      <description><![CDATA[摘要1基于Transformer的架构在自然语言处理、计算机视觉和多模式学习方面取得了显著成功，但它们面临着持续的挑战，如高计算复杂性和对动态环境的有限适应性。状态空间模型（SSM）已成为一种有竞争力的替代方案，提供线性时间复杂性和隐式捕获长期依赖关系的能力。在此基础上，Mamba模型引入了时变参数化，结合选择性状态更新、内容感知扫描策略和硬件高效设计，根据输入上下文动态调整状态转换。与基于Transformer和传统SSM架构相比，这些创新使Mamba能够保持线性复杂性，同时提供更高的吞吐量和显著降低的内存消耗。本次调查系统地回顾了曼巴模型的理论基础、建筑创新和应用进展。首先，我们追溯了SSM的演变，强调了支撑Mamba动态状态转换和选择性计算机制的关键设计原则。其次，我们总结了Mamba在建模动力学和多模态融合方面的结构创新，将其应用分类为多种模态，包括视觉、语音、点云和多模态数据。最后，我们评估了医学图像分析、推荐系统、强化学习和生成建模中的代表性应用，确定了优势、局限性和开放性挑战。该综述最后概述了未来的研究方向，重点是提高泛化、因果推理、可解释性和计算效率。这项工作旨在为研究人员和从业者提供简洁而全面的参考，促进基于Mamba的架构在不同现实世界场景中的进一步开发和部署。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S156625352501156X?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:09 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[ST Imputer：基于物理指导的多变量依赖感知扩散网络，用于时空插补]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011467?dgcid=rss_sd_all</link>
      <description><![CDATA[数据准备对于在深度学习中获得最佳结果至关重要。不幸的是，在准备大规模时空数据库时，丢失值很常见。大多数现有的插补方法主要侧重于探索单源数据的时空相关性;然而，单源数据中的高缺失率导致分布稀疏。此外，现有方法通常侧重于单一尺度上的浅相关性，限制了插补模型有效利用多尺度空间特征的能力。为了应对这些挑战，我们提出了一种名为ST-Imputer的多变量依赖感知时空插补模型。具体而言，我们引入多源上下文数据，为目标数据（即需要插补的数据）提供足够的相关性特征，缓解了单一源数据中高缺失率导致的可用特征不足的问题。通过应用多变量时空依赖性提取模块，ST Imputer捕获了不同空间尺度之间的潜在关联。随后，噪声预测模块利用学习到的双视图特征来制定时空传输模块，从而减少由过度噪声引起的权重误差。最后，应用物理约束来防止不切实际的预测。在三个大规模数据集上进行的广泛实验证明了ST Imputer的显著优势，RMSE提高了13.07%。我们的模型代码可以在https://github.com/Lion1a/ST-Imputer .]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011467?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:06 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[人再识别的视觉语言模型：调查与展望]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011571?dgcid=rss_sd_all</link>
      <description><![CDATA[人员重新识别（ReID）是一项关键任务，旨在通过多个不重叠的摄像头检索感兴趣的个人。以前的方法通常依赖于预先训练的视觉模型作为骨干，然后在人ReID数据集上进行微调，以提取判别特征。然而，由于预训练视觉模型中视觉和文本模式之间缺乏语义对齐，这些方法在有效利用这些模式之间的关系进行ReID任务方面面临挑战。近年来，视觉语言模型（VLMs）因其能够捕捉视觉和语言信息之间的丰富相关性而受到广泛关注。受到这种潜力的启发，许多研究人员提出了一系列基于VLM的方法来解决人ReID的各种挑战。本文对用于人ReID的VLMs进行了系统综述。具体而言，我们全面概述了常用的VLM框架和微调策略，同时深入分析了VLM在处理人员ReID任务方面的优势。在此基础上，我们进一步对现有的基于VLM的人ReID方法进行了广泛的分析。基于人ReID中涉及的模态和学习方法，我们将现有的基于VLM的方法分为五种主要方法：基于图像、基于视频、跨模态、多场景和无监督的人ReID方法。最后，我们概述了VLMs应用于人ReID的关键研究挑战和未来研究的潜在方向。我们相信，这篇综述将提供宝贵的见解，并为该领域的研究人员提供重要的参考。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011571?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:03 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于注意力特征聚合的GNN节点分类数据增强]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011510?dgcid=rss_sd_all</link>
      <description><![CDATA[图神经网络（GNN）在图的分类任务中取得了显著的成功，包括图像识别、视频分析和推荐系统等多媒体应用。然而，大多数GNN方法都假设样本的类别是平衡的，这与现实世界的类分布相矛盾。在实践中，不平衡的类别分布通常会导致GNN在训练过程中忽略少数类节点，从而对整体分类性能产生负面影响。现有方法仍然面临关键挑战，包括特征学习不足和节点同质性生成不足。为了应对这些挑战，我们提出了GraphAFA，这是一种基于图的新方法，它利用注意力特征a聚合来生成少量的合成类节点，从而促进样本平衡。GraphAFA由两个关键组件组成：基于注意力的特征提取和邻居感知节点聚合。首先，GraphAFA构建了一个特征空间，并利用注意力机制提取节点特征，从而能够有效地学习节点之间的高阶关系。其次，在节点生成过程中，GraphAFA聚合来自相邻节点的信息以捕获共享特征，确保新生成的节点更加同质，并降低生成异质样本的风险。最后，GraphAFA将边连接到新生成的节点，将它们集成到图中以进行下游分类。在三个基准数据集上的综合实验表明，GraphAFA在类不平衡节点分类方面始终优于最先进的方法。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011510?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:51:00 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[MFF-MTT：一种基于多特征融合的机动目标跟踪深度学习算法]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011558?dgcid=rss_sd_all</link>
      <description><![CDATA[在目标跟踪应用中，由于缺乏先验知识，传统的模型驱动算法存在模型失配的问题。最近，一些数据驱动算法在处理不确定目标机动行为方面显示出越来越大的潜力。为了进一步增强对高机动性的鲁棒性，我们提出了一种基于多特征融合的深度学习算法用于机动目标跟踪（MFF-MTT），该算法结合了卷积和变换网络。其中，卷积网络提取局部信息以捕捉快速变化状态的转换规律。变压器网络中的多头自注意（MHSA）使MFF-MTT能够通过加权输入序列的不同部分并整合查询、键和值的不同子空间表示来利用全局信息。然后以合并和交叉两种形式融合局部和全局特征，共同捕捉轨迹的短期机动和长期趋势。此外，我们还开发了一种新的编解码器框架，通过双向长短期记忆（Bi-LSTM）对融合特征进行解码。通过这种方式，可以全面了解数据的固有结构，以促进高精度的状态估计。大量仿真结果表明，在机动目标跟踪场景中，所提出的MFF-MTT在估计精度和鲁棒性方面优于其他比较方法。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011558?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:57 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[MoMD变压器：通过振动电流信号的知识传递进行自适应多模态故障诊断]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011418?dgcid=rss_sd_all</link>
      <description><![CDATA[故障诊断对于确保制造业机电系统的可靠和安全运行至关重要。近年来，基于多模态数据融合的故障诊断方法取得了显著进展。然而，这些方法对工业场景施加了额外的约束，因为它们需要在推理阶段同时输入多模态数据，这限制了它们在操作过程中只能进行单模态数据采集的情况下的适用性。为了克服这一局限性，本文提出了一种新型的混合模态诊断（MoMD）变压器，用于振动和电流信号的自适应多模态故障诊断。在该模型中，我们将Transformer中的前馈网络改进为多通道结构，以自适应地处理多种模态。此外，为了解决当前模态中弱故障特征的挑战，我们设计了一个全局知识转移模块，该模块利用振动特征来指导当前信号的特征学习。具体来说，我们对特征对齐策略的综合分析表明，对于故障数据，一对一范式优于对比学习范式，因为其类内方差较低。此外，为了提高时间序列信号的表示能力，在训练阶段引入了掩蔽信号建模任务，从而提高了诊断精度。在两个数据集上的实验结果表明，所提出的方法实现了卓越的诊断准确率，分别达到99.96%和100%，在各种模态可用性场景中优于其他方法。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011418?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:55 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[TPIN：基于文本的并行交互网络，具有通用模态和特定模态，用于多模态情感分析]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011492?dgcid=rss_sd_all</link>
      <description><![CDATA[学习有效的联合表示是多模态情感分析（MSA）的基础。现有的研究通常采用复杂的网络直接构建联合多模态表示，但往往忽视了不同模态之间的异质性以及模态特定信息的保存。此外，目前的方法倾向于平等对待所有模态，未能利用文本模态中丰富的情感线索。为了解决这些问题，我们提出了一种基于文本的并行交互网络（TPIN），旨在权衡不同模式的共性和特异性。TPIN由两个部分组成：模态通用信息处理（MCIP）和模态特定信息处理（MSIP）。在MCIP中，我们创新性地提出了一种带有硬否定挖掘（HNM）的对比学习算法，该算法被集成到我们设计的两阶段对比学习（TSCL）中，以减轻模态间的异质性。此外，我们设计了一个文本引导的动态语义聚合（TG-DSA）模块，以在文本模态的指导下实现深度多模态融合。在MSIP中，我们设计了一种动态路由机制，该机制迭代优化路由权重，以更好地捕获视觉和声学模态中的模态特定信息。实验结果表明，我们的方法在CMU-OSI和CMU-MOSEI数据集上都达到了最先进的性能，与最近的先进模型相比，在主要评估指标上显示出0.5%-1.2%的一致增益。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011492?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:52 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM中不确定性估计的调查——来源、方法、应用和挑战]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011194?dgcid=rss_sd_all</link>
      <description><![CDATA[大型语言模型（LLM）在广泛的领域中表现出了卓越的性能。然而，在金融和医疗保健等高风险领域，输出的不准确可能会导致严重后果，错误可能会导致金钱、时间甚至生命的损失。因此，最近的研究越来越关注LLM中的不确定性估计，旨在量化给定特定输入的模型生成内容的可信度。尽管人们对LLM的兴趣日益浓厚，但对LLM中不确定性的来源仍然知之甚少。因此，本次调查从不确定性来源的角度全面概述了LLM的不确定性估计，为进入该领域的研究人员提供了基础资源。我们首先回顾了LLM的基本背景，然后详细澄清了与之相关的不确定性来源。然后，我们介绍了各种不确定性估计方法，包括常用方法和LLM特定方法。讨论了评估不确定性的指标以及关键应用领域。最后，我们强调了主要挑战，并概述了旨在提高LLM可信度和可靠性的未来研究方向。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011194?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:50 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[寄生虫：通过区分特征推拉来植入持久的后门，以防止持续的联邦模型融合]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011431?dgcid=rss_sd_all</link>
      <description><![CDATA[联邦学习（FL）由于其分布式特性，容易受到后门攻击，因此需要进一步研究以了解和应对这些威胁。不幸的是，现有的研究存在后门耐久性有限的问题，因为它们的后门特征在攻击停止和良性模型融合继续后无法充分保持可辨别性。为了解决这个问题，我们提出了一种新的基于判别特征推拉的FL后门攻击框架，即Parasite，以执行持久有效的后门攻击。具体来说，我们首先提出了一个目标对齐的触发器生成模块，该模块将后门特征拉得更接近目标类良性特征，生成触发器作为后门注入的先验，以帮助植入更强的后门。然后，我们提出了一种边界分离的后门注入模块，该模块将目标类特征推离其他特征，同时将非目标移位特征拉到与预先中毒的特征对齐，从而在对效用影响最小的情况下提高后门的耐用性。大量实验表明，Parasite实现了高攻击成功率，并注入了比SOTA基线更持久的后门（例如，在CIFAR-10和GTSRB上分别高达4.16×和16.06×寿命）。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011431?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:47 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态脑网络分析：研究进展与挑战]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011583?dgcid=rss_sd_all</link>
      <description><![CDATA[脑网络分析已成为神经科学中表征大脑区域结构和功能组织的有力方法。神经影像学技术的进步，包括结构磁共振成像（sMRI）、功能磁共振影像（fMRI）、弥散张量成像（DTI）和脑电图（EEG），在不同的时间和空间尺度上提供了关于大脑解剖结构、连接模式和电生理动力学的补充信息。虽然单峰分析提供了有价值的见解，但它们在捕捉大脑网络的复杂性和动态方面存在固有的局限性。因此，多模态融合策略对于构建更准确和信息量更大的脑网络模型至关重要，从而实现了神经系统疾病分类、脑年龄预测和认知功能评估等应用。在这篇综述中，我们系统地调查了用于大脑网络分析的当代深度学习架构，包括传统框架和大型语言模型等新兴技术。我们进一步回顾了多模态融合策略，重点介绍了最近的方法学进展、它们与临床和认知应用的相关性，以及可解释性在增强模型理解和揭示神经机制方面的作用。我们还讨论了开放的技术挑战，并考虑了未来研究的潜在方向，包括解决个体差异和确保多模态脑网络建模中数据隐私和安全的策略。这篇综述为寻求推进复杂脑网络的理解和实际应用的研究人员提供了全面和前瞻性的参考。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011583?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:44 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于原型分离的跨模态哈希注意驱动对比学习]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011406?dgcid=rss_sd_all</link>
      <description><![CDATA[由于多媒体数据的指数级发展，异构数据的有效检索和结构化变得更加困难。数据量的激增强调了高效跨模态哈希技术的重要性，该技术以其快速的检索速度和最低的存储要求而闻名，最近引起了人们的关注。然而，现有的无监督跨模态哈希方法往往无法捕获潜在的语义结构和有意义的模态交互，这限制了它们的检索性能。为了应对这些挑战，我们提出了通过原型分离进行跨模态哈希的注意力驱动对比学习（ACoPSe）。该方法引入了一种模态感知融合机制来增强跨模态特征交互，并引入了一个原型对齐策略，通过利用从聚类中导出的伪标签来减少聚类级别的异质性。大量实验表明，我们的方法实现了与最先进方法相当的性能。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011406?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:41 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[EBMADPG:基于Shapley的可解释移动目标防御，通过联合贝叶斯马尔可夫博弈和DRL实现边缘智能SIoT系统]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011637?dgcid=rss_sd_all</link>
      <description><![CDATA[支持边缘智能（EI）的社交物联网（SIoT）越来越容易受到复杂恶意软件的攻击，这些恶意软件利用设备之间的社交关系快速传播并绕过传统安全。为了应对不完全信息下的这种动态威胁，我们提出了一种基于贝叶斯马尔可夫博弈的新型运动目标防御框架。在我们的框架中，防御者在检测到潜在威胁时动态地改变系统配置和资源分配。根据他们对攻击者类型的信念状态，每个防御者都可以决定是否与其他代理协调防御策略。与大多数现有工作不同，我们明确地考虑了攻击者能力的不完整信息和启用EI的SIoT系统的动态特性。我们制定了一个联合优化问题，通过贝叶斯推理、防御参数的动态重构和代理之间的最优协调策略，同时确定关于攻击者类型的信念更新。为了有效地解决这个问题，我们开发了一种新的可解释的贝叶斯多智能体深度确定性策略梯度算法，该算法将集中训练与分散执行相结合。此外，我们结合Shapley加法解释来分析代理的贡献。理论分析和广泛的模拟表明，我们提出的解决方案明显优于传统的强化学习算法。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011637?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:39 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于深度学习的天文多模态数据融合综述]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011650?dgcid=rss_sd_all</link>
      <description><![CDATA[随着观测技术的快速发展和大规模巡天的广泛实施，各种电磁波数据（如光学和红外）和非电磁波数据，如引力波，变得越来越容易获取。天文学因此进入了一个前所未有的数据丰富和复杂的时代。天文学家长期以来一直依赖单峰数据分析来感知宇宙，但在面对当前海量和异构的天文数据时，这些努力往往只能提供有限的见解。在此背景下，多模态数据融合（MDF）作为一种新兴方法，通过整合不同模态的信息，为提高天文数据的价值和深化对宇宙的理解提供了新的机会。人工智能（AI），特别是深度学习（DL）的最新进展极大地加速了天文学多模态研究的发展。因此，及时审查这一领域至关重要。本文首先讨论了天文MDF的动机和必要性，然后概述了天文数据源和主要数据模式。然后介绍了天文多模态研究中常用的代表性DL模型、一般融合过程以及各种融合策略，强调了它们的特点、适用性、优势和局限性。随后，本文对现有的天文多模态研究和数据集进行了调查。最后，讨论部分综合了主要发现，确定了潜在的挑战，并为未来的研究提出了有前景的方向。通过提供结构化的概述和批判性分析，本综述旨在激励和指导从事天文学中基于DL的MDF的研究人员。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011650?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:36 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于深度神经网络的表格数据空间编码方法综合基准]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011509?dgcid=rss_sd_all</link>
      <description><![CDATA[尽管深度神经网络在感知数据上取得了成功，但它们在表格数据上的性能仍然有限，传统模型仍然优于它们。一个有前景的替代方案是将表格数据转换为合成图像，从而能够使用卷积神经网络（CNN）和视觉变换器（ViTs）等视觉架构。然而，文献中缺乏一个大规模的、标准化的基准来评估这些转换技术。这项工作首次对24个不同的回归和分类数据集中的9种空间编码方法进行了全面评估。我们在具有严格超参数优化的统一框架下评估性能、可扩展性和计算权衡。我们的结果揭示了由样本大小（N）和维度（d）定义的数据制度构建的性能格局，并表明转换方法对预测性能的影响明显强于所选的视觉架构。特别是，REFINED是跨任务和数据集的最稳健的转换。混合模型（CNN+MLP、ViT+MLP）持续降低预测方差，尤其在较小的数据集中具有优势，但起着次要作用。这些发现表明，将表格数据转换为合成图像是一种强大但依赖于数据的策略。该基准为研究人员和从业者提供了明确的指导，提供了对可扩展性、转换行为和架构相互作用的关键见解，为未来表格数据空间编码的研究提供了全面的参考。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011509?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:33 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[脑网络分析中特征选择的不确定性感知多视图证据融合]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011455?dgcid=rss_sd_all</link>
      <description><![CDATA[由于缺乏可靠的生物标志物，精神分裂症的准确诊断仍然具有挑战性。来自静息状态fMRI的动态功能连接（dFC）提供了时间脑动力学的强大表示;然而，其固有的多视图结构带来了严峻的挑战，包括高维度、跨视图的异构性以及预处理引起的不确定性。这种不确定性直接影响特征选择，因为不可靠的特征可能会降低诊断准确性和可解释性。然而，大多数现有的特征选择方法都无法明确地建模和利用不确定性。为了应对这些挑战，我们提出了一种基于证据理论的多视图特征选择方法，该方法在捕获视图间一致性和互补性的同时，明确地模拟了不确定性。这种方法能够选择共享和视图特定的判别模式，这些模式在动态脑网络分析中经常被忽视。我们进一步引入了信息论一致性约束来提取可靠的共享信息，并引入了基于狄利克雷分布的不确定性加权损失来优先考虑具有较低不确定性的互补特征。通过证据融合跨视图集成置信度度量，我们的方法有效地量化并利用不确定性来优化特征选择。在三个独立的rs-fMRI精神分裂症数据集上进行的广泛实验表明，分类的准确性和稳健性得到了提高，为神经精神病研究中识别生物标志物提供了一种可解释和可靠的工具。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011455?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:30 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于结构化多视图最小二乘支持向量分类的分层跨模块知识转移]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011613?dgcid=rss_sd_all</link>
      <description><![CDATA[多视图学习因其能够利用来自不同数据源的补充信息而在机器学习中引起了极大的关注。然而，多视图最小二乘支持向量机（MvlSSVM）存在两个关键局限性。首先，它们对成对视图比较的依赖阻碍了它们捕获复杂视图间关系的能力。其次，与超参数调整相关的高计算成本阻碍了它们的可扩展性。为了应对这些挑战，本文提出了一种基于分层转移的结构多视图最小二乘支持向量分类（HT-SMLSSVC）。受先前关于多视图结构大边缘分类器（MvSLMC）的工作的启发，提出的HT-SMLSSVC通过加权策略和聚类实现了每一层的互补性和一致性原则，这些原则用于形成结构正则化。这个术语可以增强每个视图中的类内凝聚力和类间可分离性。同时，不同的视图相互提供互补的结构信息，从而丰富了分类器的多样性，进一步避免了对成对视图比较策略的依赖。不同之处在于模型的每一层都采用了最小二乘损失，因此超平面的解是一组线性方程，而不是标准的二次规划问题。此外，通过深度堆叠架构实现了分层知识转移，该架构传播跨层预测以提高泛化能力。同时，通过随机超参数分配和自适应验证实现了高效学习，消除了手动调整的需要，从而显著减少了模型训练时间。在17个UCI和45个AWA数据集上进行的广泛实验表明，HT-SMLSSVC在计算效率和分类精度方面都优于最先进的方法，为现实世界的多视图任务提供了可扩展的解决方案。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011613?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:28 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于塔克张量分解的转移学习多源信息融合用于手写阿尔茨海默病检测]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011741?dgcid=rss_sd_all</link>
      <description><![CDATA[随着阿尔茨海默病在全球影响约5000万人，早期发现已成为老龄化社会中至关重要的公共卫生优先事项。本文提出了一种新的基于手写的阿尔茨海默病检测的多级信息融合框架，解决了数据稀缺和高维特征表示的基本挑战。我们的方法集成了：（1）通过张量表示进行结构融合，保留手写数据的多维性质，（2）通过Tucker分解进行特征级融合，在保持判别信息的同时实现80%的参数减少，（3）通过我们提出的可转移源域检测算法进行知识融合，该算法选择性地整合了相关领域的相关知识，以及（4）采用两阶段转移debias机制的决策级融合，该机制减轻了负转移风险。在DARWIN数据集上的实验表明，我们的迁移学习方法实现了93.33%的准确率和99.10%的灵敏度，大大优于现有的基于手写的AD检测方法（最佳报告：准确率88.29%，灵敏度90.28%）。该框架在小样本场景中表现出卓越的鲁棒性，仅用10%的训练数据就保持了87.50%的准确性。我们的综合分析揭示了运动学特征的重要性得分为35.3%，而时间特征共同贡献了25.7%，其中总时间（9.4%）是时间类别中的关键标志。该框架为老年人群的早期阿尔茨海默氏症检测提供了一种有前景的非侵入性方法，有可能促进早期干预和大幅降低医疗成本。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011741?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:26 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于领域广义知识融合的风格增强大规模视觉模型在粉末床增材制造中的异常检测]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011704?dgcid=rss_sd_all</link>
      <description><![CDATA[金属增材制造（AM）彻底改变了各个行业复杂零件的生产，但确保一致的质量仍然是一个重大挑战。本研究解决了金属AM工艺中可靠有效的异常检测的关键问题，这对于保持产品质量和减少昂贵的生产后检查至关重要。在这项研究中，我们提出了一种新的全生命周期泛化方法，即风格增强的大规模视觉模型（SLVM），用于金属增材制造中的异常检测。我们的方法利用了大规模视觉模型的强大功能，并结合了基于风格的增强技术来增强AM过程中异常的检测。预训练的大规模视觉模型是SLVM的支柱，它提供了强大的特征提取能力，对于捕捉AM图像中的复杂细节至关重要。在此基础上，样式增强模块生成输入图像的不同样式化版本，显著提高了模型在不同AM工艺和材料中的泛化能力。异常检测头利用这些风格增强的特征来有效地识别和定位缺陷，从而完成AM质量控制的综合方法。我们在多个金属AM数据集上评估了我们的SLVM，包括激光粉末床熔融和粘合剂喷射工艺，证明了其与现有最先进方法相比的优越性能。我们的实验表明，SLVM实现了更高的检测精度，在不同的AM过程中具有更好的泛化能力，并提高了对零件几何形状和材料特性变化的鲁棒性。所提出的SLVM为加强金属AM的质量控制提供了一种有前景的解决方案，有可能减少对昂贵的生产后检查的需求，并提高整体制造效率。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011704?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:23 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[基于双语义编码器的子图生物医学知识嵌入用于多类型药物相互作用预测]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011716?dgcid=rss_sd_all</link>
      <description><![CDATA[识别多种药物相互作用（DDI）可以更精确地评估药物安全风险，并为联合治疗提供有针对性的指导，使其成为药理学中的一项关键任务。鉴于它可以直接整合各种生物医学信息，并有效地模拟药物相互作用背后的复杂机制，基于知识图（KG）的方法已经出现，用于预测DDI。最近的进展在这方面显示出巨大的希望;然而，现有的解决方案仍然忽视了三个关键问题：1）忽视信息稀疏性，2）忽视多元相互作用，3）缺乏融合范式，严重阻碍了对药物相互作用模式的全面识别和理解。为了解决这些问题，我们引入了一个用于多类型DDI预测的Bi-Sem antic enco D二次生成知识的U b G图表示学习框架（Bi-SemDRUG）。Bi-SemDRUG提出了一种多视图知识子图划分策略，从大规模知识图中提取与药物相关的精细拓扑结构，从而减少无关信息的干扰。此外，Bi-SemDRUG结合了一个双语义子图编码器，有效地揭示了知识子图中嵌入的多阶语义关系。最后，我们提出了一种信息融合的一般范式，以促进多层次毒品相关信息的整合。在三个基准数据集上的详尽实验表明，与其他基线方法相比，我们提出的模型实现了最先进的性能，并在大规模DDI预测中表现出良好的泛化能力。此外，案例研究强调其能够更全面地了解DDI的潜在机制。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011716?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:21 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[社交媒体上的网络模因：全面回顾和新视角]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011649?dgcid=rss_sd_all</link>
      <description><![CDATA[互联网模因已经成为一种占主导地位但复杂的在线交流形式，刺激了计算研究的快速增长。然而，现有的调查在很大程度上仍局限于狭义的分类任务，未能反映多模态大型语言模型（MLLM）引入的范式转变。为了解决这一差距，我们引入了TriR框架，包括重新定义、重新巩固和革命。在这个框架内，我们通过对模因理解的高阶认知任务进行分类，重新定义了研究范围，围绕MLLM的独特能力重新巩固了零散的方法论进展，并阐明了一个轨迹，突出了推进组合和推理建模的关键挑战和机遇。通过提供这种结构化的视角，该调查锚定了该领域的现状，同时为其未来的发展提供了系统的指导，促进了计算严谨、基于经验和道德负责的研究。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011649?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:50:18 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[ChatAssistDesign:一种通过条件扩散生成迭代向量平面图的语言交互框架]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011534?dgcid=rss_sd_all</link>
      <description><![CDATA[建筑设计是一个复杂的优化过程，需要熟练的建筑师进行迭代修改，越来越多地利用计算工具。虽然深度生成模型在自动生成平面图方面显示出希望，但仍然存在两个关键局限性：（1）依赖领域专业知识，为非专家创造了很高的技术障碍，以及（2）缺乏迭代细化能力，限制了生成后的调整。为了应对这些挑战，我们提出了ChatAssistDesign，这是一个交互式文本驱动框架，结合了（1）Floorplan Designer，一个引导用户完成设计工作流程的大型语言模型（LLM）代理，以及（2）ConDiffPlan，一个用于布局生成的基于向量的条件扩散模型。大量的实验结果表明，我们的框架在布局多样性、视觉真实性、文本到布局对齐精度方面比最先进的方法有了显著改进，更重要的是，它能够支持迭代细化，同时保持对约束冲突的高鲁棒性。通过将设计复杂性从用户技能中抽象出来，并实现动态的事后编辑，我们的方法降低了进入壁垒，并改善了与下游任务的集成。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011534?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:48 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[<u> VLDBench</u>通过监管一致性评估多模态虚假信息]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011546?dgcid=rss_sd_all</link>
      <description><![CDATA[随着人工智能工具使合成内容易于生成和传播，检测混合了操纵文本和图像的虚假信息变得越来越具有挑战性。虽然大多数现有的人工智能安全基准都集中在单模态错误信息（即无意欺骗而共享的虚假内容）、有意多模态虚假信息，如模仿可信新闻的宣传或阴谋论;在很大程度上仍未得到解决。在这项工作中，我们介绍了视觉L语言D信息检测基准点（VLDBench），这是第一个支持单峰（仅文本）和多峰（文本+图像）虚假信息检测的大规模资源。VLDBench由来自58家新闻媒体的13个类别的约62000个标记的文本图像对组成。22位领域专家使用半自动流程，然后进行专家评审，投入了500多个小时来生成高质量的注释，并达成了大量注释者之间的一致意见。对VLDBench上最先进的LLM和VLM的评估表明，添加视觉线索可以提高检测精度，从强基线的5分（例如，LLaMA-3.2-11B-视觉74.82%对LLaMA-3.2.1B-指令70.29%）到较小家庭的25-30分（例如LLaVA-v1.5-Vicuna7B 72.32%对Vicuna-7B-v1.5 55.21%），反映了图像的补充证据（例如，模因类视觉效果、图像文本一致性），这些证据是文本本身无法捕捉到的。我们为评估、微调和稳健性测试提供数据和代码，以支持虚假信息分析。VLDBench是根据人工智能治理框架（麻省理工学院人工智能风险库）开发的，为在多模式媒体中推进可信赖的虚假信息检测提供了原则基础。图16项目：https://vectorinstitute.github.io/VLDBench/图17数据：https://huggingface.co/datasets/vector-institute/VLDBench图18代码：https://github.com/VectorInstitute/VLDBench]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011546?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:46 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[GCEPANet：一种用于光学SAR图像融合的轻量级高效遥感图像去云网络模型]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011522?dgcid=rss_sd_all</link>
      <description><![CDATA[为了减轻光学遥感图像中的严重云干扰，并解决在卫星平台上部署复杂云去除模型的挑战，本研究提出了一种轻量级的门控并行注意力网络GCEPANet。通过整合光学和SAR数据，该网络充分利用了SAR图像的穿透能力，并将门控卷积模块（GCONV）与增强并行注意力模块（EPA）相结合，建立了一种“云感知-云细化”的协作机制。该机制使模型能够根据云强度识别和过滤特征，有效地分离晴朗和阴天的特征流，并自适应地补偿云引起的退化，以重建地表物体的真实结构和辐射特征。此外，引入了联合光谱-结构损失，以同时约束光谱一致性和结构保真度。在SEN12MS-CR数据集上进行的广泛实验表明，所提出的GCEPANet在多个指标上始终优于现有方法，包括PSNR、SSIM、MAE、RMSE、SAM和ERGAS。与SCTCR模型相比，GCEPANet的PSNR提高了0.9306 dB，参数数量减少了85.5%（至12.77M），FLOP减少了76.0%（至9.71G）。这些结果表明，所提出的方法在显著降低模型复杂性的同时实现了卓越的云去除性能，为光学SAR融合遥感图像中的实时在轨云去除提供了一种高效实用的解决方案。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011522?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:43 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[用于视频时刻检索的跨度感知时间聚合网络]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011376?dgcid=rss_sd_all</link>
      <description><![CDATA[视频时刻检索（VMR）旨在识别未修剪视频中语义上与自然语言查询相对应的时间跨度。现有的方法往往忽略了时间不变性，使其对查询跨度的变化敏感，并限制了其性能，特别是在检索短跨度矩时。为了解决这一局限性，我们提出了一种跨度感知的时间聚合（STA）网络，该网络引入了跨度感知特征来捕获时间不变模式，从而增强了对不同查询跨度的鲁棒性。STA由两个关键组件组成：（i）跨度感知特征聚合（SFA）模块构建与查询对齐的跨度特定视觉表示，以生成跨度感知特征，然后将其集成到本地候选矩中;（ii）查询引导矩推理（QMR）模块，其基于查询跨度语义动态调整时间卷积的接受域，以实现细粒度推理。在三个具有挑战性的基准数据集上进行的广泛实验表明，STA始终优于最先进的方法，在短跨度时刻尤其显著。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011376?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:41 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[整合视觉和音频线索以进行情绪和性别识别：一种多模式和多任务方法]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011339?dgcid=rss_sd_all</link>
      <description><![CDATA[传统上，性别和情感识别是使用音频和视频模式独立分析的，这在融合它们的输出时带来了挑战，并经常导致计算开销和延迟增加。为了解决这些局限性，在这项工作中，我们引入了MAGNET（GeNder和情感任务的多模态架构），这是一种新颖的多模态多任务学习框架，通过同时分析音频和视觉输入来联合执行性别和情感识别。MAGNET采用软参数共享，在GradNorm的指导下平衡特定任务的学习动态。这种设计不仅通过有效的模态融合提高了识别精度，还通过利用多任务学习降低了模型复杂性。因此，我们的方法特别适合在嵌入式设备上部署，在这些设备上，计算效率和响应能力至关重要。在CREMA-D数据集上进行评估后，MAGNET始终优于单峰基线和当前最先进的方法，证明了其在高效准确的软生物特征分析方面的有效性。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011339?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:38 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[IAENet：一种基于三维点云异常检测的重要性感知集成模型]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011595?dgcid=rss_sd_all</link>
      <description><![CDATA[表面异常检测对于确保工业制造中的产品质量至关重要。虽然基于2D图像的方法取得了显著成功，但基于3D点云的检测尽管具有更丰富的几何线索，但仍然没有得到充分的探索。我们认为，关键的瓶颈是3D中缺乏与2D中相当的强大预训练基础骨干。为了弥合这一差距，我们提出了重要性感知集成网络（IAENet），这是一个将2D预训练专家与3D专家模型协同工作的集成框架。然而，天真地融合来自不同来源的预测并非易事：现有的策略可能会受到表现不佳的模态的影响，从而降低整体准确性。为了应对这一挑战，我们引入了一种新的重要性感知融合（IAF）模块，该模块动态评估每个源的贡献并重新加权其异常分数。此外，我们设计了关键损失函数，明确指导IAF的优化，使其能够结合源专家的集体知识，同时保持他们的独特优势，从而提高异常检测的整体性能。大量实验表明，IAENet在点级定位方面达到了最新的水平，在MVTec 3D-AD数据集上的对象级排名第二。在Eyecankes数据集上，它在两个级别上都达到了最佳性能。此外，它大大降低了假阳性率，突显了其在工业部署中的实用价值。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011595?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:36 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[电网检测中小样本和小尺寸绝缘子烧痕的RGB点云融合尺寸补偿]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011674?dgcid=rss_sd_all</link>
      <description><![CDATA[为了应对电力基础设施检查中烧痕样本稀缺的挑战，我们引入了绝缘体烧痕RGB点云（IBMR）数据集，这是第一个公开可用的基准，具有绝缘体和烧痕像素级注释的RGB点云。为了解决由大量背景点和小尺寸烧痕引起的严重类别不平衡的关键问题，我们提出了一种新的两阶段RGB点云分割框架。该框架集成了DCCU采样和BB回溯，DCCU采样是一种创新的下采样算法，可有效抑制背景点，同时保留目标的关键结构，BB回溯是一种几何恢复方法，可重建下采样过程中丢失的细粒度烧痕细节。实验结果验证了该框架的有效性，32个训练样本的mIoU达到81.21%，仅14个样本的mIuU达到68.37%。该数据集可在以下网址公开获取https://huggingface.co/datasets/Junqiu-Tang/IBMR .]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011674?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:33 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[通过大规模综合预训练弥合射频定位中的模拟与实际差距]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011662?dgcid=rss_sd_all</link>
      <description><![CDATA[射频（RF）指纹识别是一种有前景的GPS拒绝环境定位技术，但它往往存在一个根本的局限性：对以前未映射的区域的泛化能力差。传统方法，如k-最近邻（k-NN），在数据可用的情况下表现良好，但在看不见的街道上可能会失败，限制了现实世界的部署。深度学习（DL）通过学习泛化的空间RF模式提供了潜在的补救措施，但需要比简单的现实世界测量活动所能提供的更多的训练数据。本文研究了合成数据是否可以弥合这种泛化差距。我们使用（i）来自罗马的真实世界数据集和（ii）NVIDIA的开源光线追踪模拟器Sionna，在不同的真实性和比例条件下生成合成数据集。具体来说，我们使用包含真实基站（BS）和真实信号的真实世界测量值的数据集A，并使用真实基站位置但模拟信号创建数据集B，使用模拟基站位置和信号创建数据集中C，以及表示数据集B优化版本的数据集B&#39;，其中BS参数通过高斯过程进行校准，以最大限度地提高与数据集A的信号相关性。尽管如此，对合成数据进行预训练可以将真实世界的定位误差从323m减少到162m;比纯训练提高了50%。值得注意的是，模拟保真度比规模更重要：较小的校准数据集（53K个样本）的表现优于较大的未校准数据集。为了进一步评估模型的泛化能力，我们使用奥斯陆的真实数据集在一个看不见的地理区域进行了实验。在零样本设置中，对奥斯陆数据进行微调后，模型在整个数据集上的均方根误差（RMSE）为132.2米，在看不见的街道上的均方误差为61.5米。虽然在达到更实际的定位精度之前仍然存在挑战，但这项工作在射频定位中的合成到真实传输的无线通信领域提供了一项系统研究，并强调了模拟感知预训练对于将DL模型推广到现实世界场景的价值。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011662?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:31 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[DepressionInstruct：用于抑郁症检测的大型语音语言模型的指令调优]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S156625352501139X?dgcid=rss_sd_all</link>
      <description><![CDATA[抑郁症是心理健康领域的一个重大全球性问题，推动了对基于人工智能的诊断和检测方法的广泛研究。在各种人工智能技术中，大型语言模型（LLMs）因其强大的泛化能力和通用性而脱颖而出。然而，这些模型的主要局限性之一是它们完全依赖文本输入，这在一定程度上限制了它们的整体性能。此外，LLM通过结合原始语音信号分析抑郁状态的潜力尚未得到充分探索。在这篇论文中，我们提出了一种创新的方法，将不同类型的单峰信息整合到多模态描述中，从而将原始声学信息整合到大型语音语言模型中，用于多模态抑郁检测。通过结合原始语音信号、文本转录和说话者情感信息，我们构建了一个多模态指令集，并使用指令对大型语音语言模型进行微调，以识别个体的潜在心理状态。对DAIC、EATD和CMDC数据集的评估表明，DAIC、EETD和CMDC数据集的F1得分分别为0.8235、0.8182和0.9818。这些结果表明，所提出的方法在抑郁症检测方面取得了最先进的性能。此外，这种方法不仅在抑郁症检测方面具有重要价值，而且为大型语言模型理解和处理语音信号的能力提供了新的视角。本文中使用的源代码可在https://github.com/jiabing1988/instruct_fine_Qwen2_audio .]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S156625352501139X?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:28 GMT</pubDate>
    </item>
    <item>
      <title><![CDATA[生成包含细粒度对齐注释的视觉语言导航指令]]></title>
      <link>https://www.sciencedirect.com/science/article/pii/S1566253525011698?dgcid=rss_sd_all</link>
      <description><![CDATA[视觉语言导航（VLN）使智能代理能够通过集成视觉感知和自然语言指令来导航环境，但由于缺乏细粒度的跨模态对齐注释，它面临着重大挑战。现有的数据集主要关注全局指令轨迹匹配，忽略了对准确导航动作决策至关重要的子指令级和实体级对齐。为了解决这一局限性，我们提出了FCA-NIG，这是一个生成框架，可以自动构建具有双层细粒度跨模态注释的导航指令。在这个框架中，首先将增强轨迹划分为子轨迹，然后通过基于GLIP的地标检测、精心设计的指令构造、基于OFA Speaker的R2R类指令生成和CLIP驱动的实体选择来处理子轨迹，生成带有实体地标注释的子指令轨迹对。最后，这些子对被聚合形成一个完整的指令轨迹对。该框架生成了FCA-R2R数据集，这是第一个具有精确子指令子轨迹和实体地标对齐的大规模增强数据集。大量实验表明，使用FCA-R2R进行训练可以显著提高多种最先进的VLN代理的性能，包括SF、EnvDrop、RecBERT、HAMT、DUET和BEVBERT。结合子指令轨迹对齐提高了代理的状态感知和决策准确性，而实体地标对齐进一步提高了导航性能和泛化能力。这些结果突显了FCA-NIG在生成高质量、可扩展的训练数据而无需手动注释方面的有效性，在复杂的导航任务中推进了细粒度的跨模态学习。]]></description>
      <guid isPermaLink="false">https://www.sciencedirect.com/science/article/pii/S1566253525011698?dgcid=rss_sd_all</guid>
      <pubDate>Wed, 14 Jan 2026 14:49:26 GMT</pubDate>
    </item>
    </channel>
</rss>